{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-experimental tiktoken langchain-openai tabulate langchain-community fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from openai import OpenAI\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Replace 'your-api-key' with your actual OpenAI API key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    ")\n",
    "# def is_api_key_valid():\n",
    "#     try:\n",
    "#         response = openai.Completion.create(\n",
    "#             engine=\"gpt-3.5-turbo-16k\",\n",
    "#             prompt=\"This is a test.\",\n",
    "#             max_tokens=5\n",
    "#         )\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "# Check the validity of the API key\n",
    "# api_key_valid = is_api_key_valid()\n",
    "# print(\"Is API key valid?:\", api_key_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"You are an expert in finding out the date terms present in any string or sentence. Given an input query, extract any phrase or word from the query that means following terms:\n",
    "1. Start Date\n",
    "2. End Date\n",
    "3. Any particular date(including today, tomorrow etc)\n",
    "After getting the phrase, convert it into the format YYYY-MM-DD and return the findings into a json file using following format:\n",
    "\n",
    "{start_date: Any start date present,\n",
    "end_date: Any end date present,\n",
    "particular_date: Any particular date present}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\",\"top_k\"], template=TEMPLATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, verbose=True,model=\"gpt-3.5-turbo-16k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
